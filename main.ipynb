{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo 3\n",
    "Alumnos:\n",
    "- Marcos Hernández Rodríguez\n",
    "- Salva ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from modules import config as cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sobre la base de datos de peatones para clasificación. Aplicar un clasificador SVM. Se deberá implementar HoG (no usar una función ya implementada). Obtener resultados de bondad del clasificador\n",
    "2. Sobre la base de datos de peatones para clasificación. Aplicar un clasificador usando una red neuronal de convolución. Se deberán reusar y modificar las arquitecturas VGG16, ResNet18 y Xception para tal fin. Obtener una comparativa de bondad usando predictores como agudeza, F1, recall, precision.\n",
    "3. Sobre la base de datos de peatones para clasificación. Compara la mejor red neuronal obtenida en el punto 2 con el clasificador SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "924\n",
      "(128, 64, 3)\n",
      "<class 'list'>\n",
      "400\n",
      "(128, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "# Preparar los datos para las imágenes con personas andando\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "pedestrians_path = 'input/classification/pedestrians128x64/'\n",
    "pedestrians_images, pedestrians_labels = h.load_images_from_folder(pedestrians_path, class_label=1)\n",
    "print(type(pedestrians_images))\n",
    "print(len(pedestrians_images))\n",
    "print(pedestrians_images[0].shape)\n",
    "\n",
    "\n",
    "# Select 400 images randomly\n",
    "import random\n",
    "pedestrians_images = random.sample(pedestrians_images, 400)\n",
    "print(type(pedestrians_images))\n",
    "print(len(pedestrians_images))\n",
    "print(pedestrians_images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esto no se si está bien\n",
    "\n",
    "import random\n",
    "random.shuffle(pedestrians_images)\n",
    "x_train = pedestrians_images[int(len(pedestrians_images)/2):]\n",
    "x_test = pedestrians_images[:int(len(pedestrians_images)/2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### no peatones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "924\n",
      "(128, 64, 3)\n",
      "<class 'list'>\n",
      "40\n",
      "(128, 64, 3)\n",
      "(128, 64, 3)\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "# Preparar los datos para las imágenes sin personas andando\n",
    "no_pedestrians_path = 'input/classification/pedestrians_neg/'\n",
    "no_pedestrians_images, no_pedestrians_labels = h.load_images_from_folder(pedestrians_path, class_label=0)\n",
    "print(type(no_pedestrians_images))\n",
    "print(len(no_pedestrians_images))\n",
    "print(no_pedestrians_images[0].shape)\n",
    "\n",
    "# Select images randomly\n",
    "import random\n",
    "no_pedestrians_images = random.sample(no_pedestrians_images, 40)\n",
    "print(type(no_pedestrians_images))\n",
    "print(len(no_pedestrians_images))\n",
    "print(no_pedestrians_images[0].shape)\n",
    "\n",
    "# Resize de las imagenes a 512x512\n",
    "import cv2\n",
    "for i, img in enumerate(no_pedestrians_images):\n",
    "    no_pedestrians_images[i] = cv2.resize(no_pedestrians_images[i], (512, 512))\n",
    "\n",
    "    # Escoger un trozo de 128x64\n",
    "    no_pedestrians_images[i] = no_pedestrians_images[i][192:320, 224:288]\n",
    "\n",
    "print(no_pedestrians_images[0].shape)\n",
    "print(len(no_pedestrians_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caracterizar la imagen usando Histograma de Orientación de Gradiente (HOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "128\n",
      "<class 'numpy.ndarray'>\n",
      "(128, 64, 3)\n",
      "<class 'int'> 128\n",
      "<class 'int'> 64\n",
      "gradient_matrix length: 128\n",
      "--- split_in_cells ---\n",
      "gradient_matrix shape: (128, 64, 2)\n",
      "cell_rows: 16\n",
      "cell_columns: 8\n",
      "result length: 0\n",
      "[0. 0.]\n",
      "[0. 0.]\n",
      "[0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\GitHub\\vision_computador\\modules\\helpers.py:56: RuntimeWarning: invalid value encountered in sqrt\n",
      "  norm = np.sqrt(0.5 * (brackets))\n",
      "c:\\Users\\marco\\GitHub\\vision_computador\\modules\\helpers.py:54: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  argument = 0.5 * np.arctan(2*gXY / (gXX-gYY))\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2540\\82406479.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m### TERCERA FASE: Obtener histograma por celda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcell_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_histogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marco\\GitHub\\vision_computador\\modules\\helpers.py\u001b[0m in \u001b[0;36mget_histogram\u001b[1;34m(cell)\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margument\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m             \u001b[0mcategories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_histogram_category\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margument\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m     \u001b[0mhistogram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnormalize_histogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "from modules import helpers as h\n",
    "\n",
    "for i, ped_img in enumerate(pedestrians_images):\n",
    "    print(i)\n",
    "\n",
    "    ### PRIMERA FASE: Obtener el gradiente de cada píxel\n",
    "    gradient_matrix = h.get_gradient_matrix(ped_img)\n",
    "    # print(f'gradient_matrix shape: {gradient_matrix.shape}')\n",
    "    print(f'gradient_matrix length: {len(gradient_matrix)}')\n",
    "\n",
    "    ### SEGUNDA FASE: Obtener la división en células\n",
    "    cell_list = h.split_in_cells(gradient_matrix, cell_size=8)\n",
    "\n",
    "    ### TERCERA FASE: Obtener histograma por celda\n",
    "    for cell in cell_list:\n",
    "        h.get_histogram(cell)\n",
    "\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2540\\570252055.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "a = np.zeros((4, 4))\n",
    "print(a)\n",
    "a[1, 1] = [4,4,4,4]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HOG_X_pos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18768\\251879158.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mHOG_X_pos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mHOG_X_neg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#Concatenación de HOG\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_pos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_neg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[1;31m#Concatenación de valor de la clase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mntrain\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;31m#cardinal del conjunto entrenamiento\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mntest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mntrain\u001b[0m\u001b[1;33m;\u001b[0m \u001b[1;31m#cardinal del conjunto test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'HOG_X_pos' is not defined"
     ]
    }
   ],
   "source": [
    "X=np.concatenate([HOG_X_pos,HOG_X_neg])#Concatenación de HOG\n",
    "y=np.concatenate([y_pos,y_neg]); #Concatenación de valor de la clase\n",
    "ntrain= round(0.8*len(y));#cardinal del conjunto entrenamiento\n",
    "ntest = len(x)-ntrain; #cardinal del conjunto test\n",
    "\n",
    "idx = np.random.permutation(np.arange(len(y))) #obtenemos una permutación\n",
    "X_train= X[idx[0:ntrain],:]; #Obtenemos barajado el conjunto entrenamiento\n",
    "y_train=y[idx[0:ntrain]] #igual para el valor de clase\n",
    "X_test= X[idx[ntrain+1:len(y)],:];#Obtenemos barajado el conjunto test\n",
    "y_test=y[idx[ntrain+1:len(y)]]; #igual para el valor de clase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "m = SVC()\n",
    "m.fit(x_train,y_train)\n",
    "\n",
    "y_pred_train=m.predict(x_train); \n",
    "\n",
    "y_pred_test=m.predict(x_test); \n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train, y_pred_train)\n",
    "confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with CNN\n",
    "\n",
    "2. Sobre la base de datos de peatones para clasificación. Aplicar un clasificador usando una red neuronal de convolución. Se deberán reusar y modificar las arquitecturas VGG16, ResNet18 y Xception para tal fin. Obtener una comparativa de bondad usando predictores como agudeza, F1, recall, precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16, ResNet18 y Xception.\n",
    "# Dijo Sara que se puede usar ResNet50 en vez de la 18 si no funciona bien la 18\n",
    "\n",
    "# usar transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 128, 64, 3)]      0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 128, 64, 64)       1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 128, 64, 64)       36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 64, 32, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 64, 32, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 64, 32, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 32, 16, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 32, 16, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 32, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 32, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 16, 8, 256)        0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 16, 8, 512)        1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 16, 8, 512)        2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 16, 8, 512)        2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 8, 4, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 8, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 8, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 8, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 2, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[]\n",
      "[16256.25 16256.25 16256.25]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 128, 64, 3)]      0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 128, 64, 3)        0         \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 128, 64, 3)       7         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 4, 2, 512)         14714688  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,715,208\n",
      "Trainable params: 513\n",
      "Non-trainable params: 14,714,695\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Utilizamos el modelo VGG16\n",
    "base_model = keras.applications.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=cf.input_shape,\n",
    "    include_top=False,\n",
    ")\n",
    "\n",
    "base_model.summary()\n",
    "\n",
    "# Congelamos capas \n",
    "base_model.trainable = False\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=cf.input_shape)\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        # Reflejo horizontal\n",
    "        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        # Rotaciones \n",
    "        tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    ]\n",
    ")\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "# Normalización\n",
    "#usando outputs = (inputs - mean) / sqrt(var)\n",
    "norm_layer = keras.layers.experimental.preprocessing.Normalization()\n",
    "mean = np.array([127.5] * 3)\n",
    "var = mean ** 2\n",
    "# mean = np.append(mean, mean[0])\n",
    "# var = np.append(var, var[0])\n",
    "print(norm_layer.get_weights())\n",
    "print(var)\n",
    "\n",
    "\n",
    "x = norm_layer(x)\n",
    "#norm_layer.set_weights([mean, var])\n",
    "\n",
    "\n",
    "x = base_model(x, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "outputs = keras.layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "epochs = 5\n",
    "history = model.fit(train_ds, epochs=epochs, validation_data=validation_ds)\n",
    "\n",
    "\n",
    "plt.plot(history.history['binary_accuracy'])\n",
    "plt.plot(history.history['val_binary_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Sobre la base de datos de peatones para clasificación. Compara la mejor red neuronal obtenida en el punto 2 con el clasificador SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation\n",
    "\n",
    "Sobre la base de datos de peatones para segmentación semántica. Partiendo de la\n",
    "arquitectura base probar diferentes modificaciones de esta. Realizar un análisis de las\n",
    "arquitecturas estudiadas:\n",
    "- Obtener en este análisis el promedio de IoU (intersection over union) a lo largo del conjunto test sobre las diferentes arquitecturas estudiadas. Obtener la agudeza.\n",
    "- Tiempo de aprendizaje.\n",
    "- Dimensión de la representación latente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El alumno/a debe tener en cuenta que las imágenes tienen diferentes dimensiones tanto en el conjunto de entrenamiento como en el conjunto test. Por lo tanto un paso previo será normalizar las imágenes a la misma dimensión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "96\n",
      "(406, 612, 3)\n",
      "(378, 745, 3)\n",
      "(418, 670, 3)\n",
      "(436, 786, 3)\n",
      "(454, 767, 3)\n",
      "<class 'list'>\n",
      "96\n",
      "(406, 612, 3)\n",
      "(378, 745, 3)\n",
      "(418, 670, 3)\n",
      "(436, 786, 3)\n",
      "(454, 767, 3)\n"
     ]
    }
   ],
   "source": [
    "# Read data training images\n",
    "data_segmentation_train_imgs_path = 'input/data_segmentation/train/images/'\n",
    "data_seg_train_imgs = h.load_images_from_folder(data_segmentation_train_imgs_path)\n",
    "print(type(data_seg_train_imgs))\n",
    "print(len(data_seg_train_imgs))\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    print(data_seg_train_imgs[i].shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Read data training masks\n",
    "data_segmentation_train_masks_path = 'input/data_segmentation/train/mask/'\n",
    "data_seg_train_masks = h.load_images_from_folder(data_segmentation_train_masks_path)\n",
    "print(type(data_seg_train_masks))\n",
    "print(len(data_seg_train_masks))\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    print(data_seg_train_masks[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "74\n",
      "(536, 559, 3)\n",
      "(414, 455, 3)\n",
      "(445, 479, 3)\n",
      "(397, 396, 3)\n",
      "(344, 335, 3)\n",
      "<class 'list'>\n",
      "74\n",
      "(536, 559, 3)\n",
      "(414, 455, 3)\n",
      "(445, 479, 3)\n",
      "(397, 396, 3)\n",
      "(344, 335, 3)\n"
     ]
    }
   ],
   "source": [
    "# Read data test images\n",
    "data_segmentation_test_imgs_path = 'input/data_segmentation/test/images/'\n",
    "data_seg_test_imgs = h.load_images_from_folder(data_segmentation_test_imgs_path)\n",
    "print(type(data_seg_test_imgs))\n",
    "print(len(data_seg_test_imgs))\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    print(data_seg_test_imgs[i].shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Read data test masks\n",
    "data_segmentation_test_masks_path = 'input/data_segmentation/test/mask/'\n",
    "data_seg_test_masks = h.load_images_from_folder(data_segmentation_test_masks_path)\n",
    "print(type(data_seg_test_masks))\n",
    "print(len(data_seg_test_masks))\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    print(data_seg_test_masks[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "96\n",
      "74\n",
      "74\n"
     ]
    }
   ],
   "source": [
    "print(len(data_seg_train_imgs))\n",
    "print(len(data_seg_train_masks))\n",
    "\n",
    "print(len(data_seg_test_imgs))\n",
    "print(len(data_seg_test_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The `pool_size` argument must be a tuple of 3 integers. Received: (2, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2540\\2155177628.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# salida de capa de 214x214x64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu_1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaxPooling3D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'maxpool_1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;31m# salida de capa de 107x107x64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv3D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"same\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'conv_2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\pooling.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, pool_size, strides, padding, data_format, **kwargs)\u001b[0m\n\u001b[0;32m    806\u001b[0m                \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m                **kwargs):\n\u001b[1;32m--> 808\u001b[1;33m     super(MaxPooling3D, self).__init__(\n\u001b[0m\u001b[0;32m    809\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool3d\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m         \u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\pooling.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, pool_function, pool_size, strides, padding, data_format, name, **kwargs)\u001b[0m\n\u001b[0;32m    680\u001b[0m       \u001b[0mstrides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpool_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pool_size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m     self.strides = conv_utils.normalize_tuple(\n\u001b[0;32m    684\u001b[0m         strides, 3, 'strides', allow_zero=True)\n",
      "\u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36mnormalize_tuple\u001b[1;34m(value, n, name, allow_zero)\u001b[0m\n\u001b[0;32m     81\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_tuple\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msingle_value\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalue_tuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The `pool_size` argument must be a tuple of 3 integers. Received: (2, 2)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras.layers import InputLayer, ReLU, Conv3D, Conv3DTranspose, Softmax, Dense\n",
    "\n",
    "# https://keras.io/api/layers/\n",
    "\n",
    "# Creamos el modelo\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "prueba_train_shape = 43 # cambiar!\n",
    "\n",
    "# Falla algo de las dimensiones\n",
    "model.add(InputLayer(input_shape=(prueba_train_shape, 214, 214, 3), name='imageinput'))\n",
    "model.add(Conv3D(64, (3,3,3), strides=(1,1,1), padding=\"same\", name='conv_1'))\n",
    "# salida de capa de 214x214x64\n",
    "model.add(ReLU(name='relu_1'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding=(0,0,0,0), name='maxpool_1'))\n",
    "# salida de capa de 107x107x64\n",
    "model.add(tf.keras.layers.Conv3D(64, (3,3,64), strides=(1,1), padding=\"same\", name='conv_2'))\n",
    "model.add(ReLU(name='relu_2'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding=(0,0,0,0), name='maxpool_2'))\n",
    "model.add(tf.keras.layers.Conv3D(64, (3,3,64), strides=(1,1), padding=\"same\", name='conv_3'))\n",
    "model.add(ReLU(name='relu_3'))\n",
    "model.add(tf.keras.layers.Conv3D(64, (3,3,64), strides=(1,1), padding=\"same\", name='conv_4'))\n",
    "\n",
    "# Capas decodificadoras\n",
    "# cropping es lo mismo que padding?\n",
    "model.add(Conv3DTranspose(64, (4,4,64), strides=(2, 2), padding=(0,0,0,0), name='transposed-conv_1'))\n",
    "model.add(Conv3DTranspose(64, (4,4,64), strides=(2, 2), padding=(0,0,0,0), name='transposed-conv_2'))\n",
    "\n",
    "model.add(tf.keras.layers.Conv3D(2, (1,1,64), strides=(1,1), padding=(0,0,0,0), name='conv_5'))\n",
    "# A continuación aplicamos una capa softmax con función de perdida entropia cruzada para obtener la clases fondo o peatón.\n",
    "model.add(Softmax(name='softmax'))\n",
    "# ? es una dense?\n",
    "model.add(Dense(1, activation='sigmoid', name='classoutput'))\n",
    "\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"BinaryCrossentropy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5e1398cdbc5000f70d27840b9ea3342abf7ef0093b1dcda8062c3b12392418e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
